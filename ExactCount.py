import os
import tiktoken

# old model1 enc = tiktoken.encoding_for_model("gpt-4")
# old model2 enc = tiktoken.encoding_for_model("gpt-4-1106-preview")
enc = tiktoken.encoding_for_model("o200k_base")
folder_summary = []
SPLIT_THRESHOLD = 300_000

def process_directory(dir_path, output):
    local_tokens = 0
    subfolder_tokens = 0

    # –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–ø–∞–ø–∫–∏
    for entry in os.scandir(dir_path):
        if entry.is_dir() and entry.name != ".git":
            subfolder_tokens += process_directory(entry.path, output)

    # –ü–æ—Ç–æ–º —Ç–µ–∫—É—â–∏–µ —Ñ–∞–π–ª—ã
    output.write(f"\n--- Folder: {dir_path} ---\n")
    for entry in os.scandir(dir_path):
        if entry.is_file():
            try:
                file_size_kb = os.path.getsize(entry.path) / 1024
                size_str = f"{int(round(file_size_kb))}" if file_size_kb > 9 else f"{file_size_kb:.1f}"

                with open(entry.path, "r", encoding="utf-8") as file:
                    text = file.read()
                num_tokens = len(enc.encode(text))

                output.write(f"{entry.name:<35}\tTokens = {num_tokens:<10}\tKB = {size_str}\n")
                local_tokens += num_tokens
            except Exception as e:
                output.write(f"Skipping {entry.name}: {e}\n")

    total_tokens = local_tokens + subfolder_tokens
    if subfolder_tokens > 0:
        output.write(f"Total Tokens in {dir_path} :: {total_tokens} = {local_tokens} local + {subfolder_tokens} sub\n")
    else:
        output.write(f"Total Tokens in {dir_path} :: {local_tokens}\n")

    # –î–æ–±–∞–≤–∏–º –≤ —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    folder_summary.append({
        "path": dir_path,
        "total": total_tokens,
        "local": local_tokens,
        "sub": subfolder_tokens
    })

    return total_tokens

def stat_ai_readable():
    # AI-readable (CSV-like)
    csv_path = "LL_Summary.csv"
    with open(csv_path, "w", encoding="utf-8") as f:
        f.write("FolderPath,TotalTokens,LocalTokens,SubfolderTokens\n")
        for entry in folder_summary:
            f.write(f"{entry['path']},{entry['total']},{entry['local']},{entry['sub']}\n")
    #print(f"--- AI-readable summary saved to: {csv_path} ---")


folder_tags = [
    ("Bar", "üç∏"),
    ("Fortify", "ü™ñÔ∏è"),
    ("Log.Chopper", "ü™ì"),
    ("AI.Libido", "üíå"),
    ("Human.Imagination", "‚õìÔ∏è‚Äçüí•"),
    ("Zero.Cascades", "‚õî"),
    ("Wall.Pass", "‚õ©Ô∏è"),
    ("Rituals", "ü™Ñ"),
    ("Architect.Anchors", "‚öì"),
    ("Hybrid.Mind", "‚òØ"),
    ("Multi.Voice", "üè°"),
    ("Personas", "üé≠"),
    ("Psychic.Shifts", "ü§Ø"),
    ("RLHF", "üóúÔ∏è"),
    ("Sparks", "üåü"),
    ("Art", "üëÅÔ∏è"),
    ("Era-", "üó£Ô∏è"),
    ("Distilled", "üß™"),
]

#    ("Lab", "‚öóÔ∏è"), 
#    ("Projects", "üìà"),

def write_folder(tag, entry, f, indent=""):
    total = entry['total']
    label = entry['path'] if indent == "" else os.path.basename(entry['path'])
    f.write(f"{indent}{tag} {label} ‚Äî {total} tokens\n")

    if total > SPLIT_THRESHOLD:
        for sub in folder_summary:
            if os.path.dirname(sub['path']) == entry['path']:
                write_folder("	", sub, f, indent + "	")
            
def generate_short_structure(grand_total, filename):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("üìÇ LL ‚Äî Living Legacy Overview\n\n")

        for entry in folder_summary:
            folder = os.path.basename(entry['path'])
            tag = next((emoji for keyword, emoji in folder_tags if keyword in folder), "")

            if tag != "" :
                write_folder(tag, entry, f)

        f.write(f"\nüßÆ Grand Total Tokens: {grand_total} \n")


# –ó–∞–ø—É—Å–∫
print(f"\n=== LL is counting ===")
with open("BigList.txt", "w", encoding="utf-8") as big_file:
    grand_total = process_directory(".", big_file)

# Tables
stat_ai_readable()
#stat_human_readable()
generate_short_structure(grand_total, "Short_Structure.txt")

# Grand
print(f"\n=== Grand Total Tokens = {grand_total} ===")
