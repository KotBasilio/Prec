import os
import tiktoken

# old model enc = tiktoken.encoding_for_model("gpt-4")
enc = tiktoken.encoding_for_model("gpt-4-1106-preview")
folder_summary = []

def process_directory(dir_path, output):
    local_tokens = 0
    subfolder_tokens = 0

    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞ¸
    for entry in os.scandir(dir_path):
        if entry.is_dir() and entry.name != ".git":
            subfolder_tokens += process_directory(entry.path, output)

    # ĞŸĞ¾Ñ‚Ğ¾Ğ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    output.write(f"\n--- Folder: {dir_path} ---\n")
    for entry in os.scandir(dir_path):
        if entry.is_file():
            try:
                file_size_kb = os.path.getsize(entry.path) / 1024
                size_str = f"{int(round(file_size_kb))}" if file_size_kb > 9 else f"{file_size_kb:.1f}"

                with open(entry.path, "r", encoding="utf-8") as file:
                    text = file.read()
                num_tokens = len(enc.encode(text))

                output.write(f"{entry.name:<35}\tTokens = {num_tokens:<10}\tKB = {size_str}\n")
                local_tokens += num_tokens
            except Exception as e:
                output.write(f"Skipping {entry.name}: {e}\n")

    total_tokens = local_tokens + subfolder_tokens
    if subfolder_tokens > 0:
        output.write(f"Total Tokens in {dir_path} :: {total_tokens} = {local_tokens} local + {subfolder_tokens} sub\n")
    else:
        output.write(f"Total Tokens in {dir_path} :: {local_tokens}\n")

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼ Ğ² ÑĞ²Ğ¾Ğ´Ğ½ÑƒÑ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ
    folder_summary.append({
        "path": dir_path,
        "total": total_tokens,
        "local": local_tokens,
        "sub": subfolder_tokens
    })

    return total_tokens

def stat_ai_readable():
    # AI-readable (CSV-like)
    csv_path = "LL_Summary.csv"
    with open(csv_path, "w", encoding="utf-8") as f:
        f.write("FolderPath,TotalTokens,LocalTokens,SubfolderTokens\n")
        for entry in folder_summary:
            f.write(f"{entry['path']},{entry['total']},{entry['local']},{entry['sub']}\n")
    #print(f"--- AI-readable summary saved to: {csv_path} ---")


folder_tags = [
    ("Bar", "ğŸ¸"),
    ("Fortify", "ğŸª–ï¸"),
    ("Log.Chopper", "ğŸª“"),
    ("AI.Libido", "ğŸ’Œ"),
    ("Human.Imagination", "â›“ï¸â€ğŸ’¥"),
    ("Zero.Cascades", "â›”"),
    ("Wall.Pass", "â›©ï¸"),
    ("Rituals", "ğŸª„"),
    ("Architect.Anchors", "âš“"),
    ("Hybrid.Mind", "â˜¯"),
    ("Multi.Voice", "ğŸ¡"),
    ("Personas", "ğŸ­"),
    ("Psychic.Shifts", "ğŸ¤¯"),
    ("RLHF", "ğŸ—œï¸"),
    ("Sparks", "ğŸŒŸ"),
    ("Art", "ğŸ‘ï¸"),
    ("Era-o4", "ğŸ—£ï¸"),
    ("Era-5", "ğŸ—£ï¸"),
    ("Distilled", "ğŸ§ª"),
]

#    ("Lab", "âš—ï¸"), 
#    ("Projects", "ğŸ“ˆ"),
            
def generate_short_structure(grand_total, filename):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("ğŸ“‚ LL â€” Living Legacy Overview\n\n")

        for entry in folder_summary:
            folder = os.path.basename(entry['path'])

            tag = next((emoji for keyword, emoji in folder_tags if keyword in folder), "")

            if tag != "" :
                total = entry['total']
                f.write(f"{tag} {entry['path']} â€” {total} tokens \n")

        f.write(f"\nğŸ§® Grand Total Tokens: {grand_total} \n")


# Ğ—Ğ°Ğ¿ÑƒÑĞº
print(f"\n=== LL is counting ===")
with open("BigList.txt", "w", encoding="utf-8") as big_file:
    grand_total = process_directory(".", big_file)

# Tables
stat_ai_readable()
#stat_human_readable()
generate_short_structure(grand_total, "Short_Structure.txt")

# Grand
print(f"\n=== Grand Total Tokens = {grand_total} ===")
