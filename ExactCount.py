import os
import tiktoken

# old model1 enc = tiktoken.encoding_for_model("gpt-4")
enc = tiktoken.encoding_for_model("gpt-4-1106-preview")
folder_summary = []
SPLIT_THRESHOLD = 500_000

def process_directory(dir_path, output):
    local_tokens = 0
    subfolder_tokens = 0

    # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÐ¸
    for entry in os.scandir(dir_path):
        if entry.is_dir() and entry.name != ".git":
            subfolder_tokens += process_directory(entry.path, output)

    # ÐŸÐ¾Ñ‚Ð¾Ð¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
    output.write(f"\n--- Folder: {dir_path} ---\n")
    for entry in os.scandir(dir_path):
        if entry.is_file():
            try:
                file_size_kb = os.path.getsize(entry.path) / 1024
                size_str = f"{int(round(file_size_kb))}" if file_size_kb > 9 else f"{file_size_kb:.1f}"

                with open(entry.path, "r", encoding="utf-8") as file:
                    text = file.read()
                num_tokens = len(enc.encode(text))

                output.write(f"{entry.name:<35}\tTokens = {num_tokens:<10}\tKB = {size_str}\n")
                local_tokens += num_tokens
            except Exception as e:
                output.write(f"Skipping {entry.name}: {e}\n")

    total_tokens = local_tokens + subfolder_tokens
    if subfolder_tokens > 0:
        output.write(f"Total Tokens in {dir_path} :: {total_tokens} = {local_tokens} local + {subfolder_tokens} sub\n")
    else:
        output.write(f"Total Tokens in {dir_path} :: {local_tokens}\n")

    # Ð”Ð¾Ð±Ð°Ð²Ð¸Ð¼ Ð² ÑÐ²Ð¾Ð´Ð½ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ
    folder_summary.append({
        "path": dir_path,
        "total": total_tokens,
        "local": local_tokens,
        "sub": subfolder_tokens
    })

    return total_tokens

def stat_ai_readable():
    # AI-readable (CSV-like)
    csv_path = "LL_Summary.csv"
    with open(csv_path, "w", encoding="utf-8") as f:
        f.write("FolderPath,TotalTokens,LocalTokens,SubfolderTokens\n")
        for entry in folder_summary:
            f.write(f"{entry['path']},{entry['total']},{entry['local']},{entry['sub']}\n")
    #print(f"--- AI-readable summary saved to: {csv_path} ---")


folder_tags = [
    ("Bar", "ðŸ¸"),
    ("Fortify", "ðŸª–ï¸"),
    ("Log.Chopper", "ðŸª“"),
    ("AI.Libido", "ðŸ’Œ"),
    ("Human.Imagination", "â›“ï¸â€ðŸ’¥"),
    ("Zero.Cascades", "â›”"),
    ("Wall.Pass", "â›©ï¸"),
    ("Rituals", "ðŸª„"),
    ("Architect.Anchors", "âš“"),
    ("Hybrid.Mind", "â˜¯"),
    ("Multi.Voice", "ðŸ¡"),
    ("Personas", "ðŸŽ­"),
    ("Psychic.Shifts", "ðŸ¤¯"),
    ("RLHF", "ðŸ—œï¸"),
    ("Sparks", "ðŸŒŸ"),
    ("Art", "ðŸ‘ï¸"),
    ("Era-", "ðŸ—£ï¸"),
    ("Distilled", "ðŸ§ª"),
    ("Emerged.Coders", "ðŸ“ˆ"),
]

#    ("Lab", "âš—ï¸"), 

def write_folder(tag, entry, f, indent=""):
    total = entry['total']
    label = entry['path'] if indent == "" else os.path.basename(entry['path'])
    f.write(f"{indent}{tag} {label} â€” {total} tokens\n")

    if total > SPLIT_THRESHOLD:
        for sub in folder_summary:
            if os.path.dirname(sub['path']) == entry['path']:
                write_folder("	", sub, f, indent + "	")
            
def generate_short_structure(grand_total, filename):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("ðŸ“‚ LL â€” Living Legacy Overview\n\n")

        for entry in folder_summary:
            folder = os.path.basename(entry['path'])
            tag = next((emoji for keyword, emoji in folder_tags if keyword in folder), "")

            if tag != "" :
                write_folder(tag, entry, f)

        f.write(f"\nðŸ§® Grand Total Tokens: {grand_total} \n")


# Start
print("=== LL is counting ===")
with open("BigList.txt", "w", encoding="utf-8") as big_file:
    grand_total = process_directory(".", big_file)

# Tables
stat_ai_readable()
generate_short_structure(grand_total, "Short_Structure.txt")

# Grand
print(f"=== Grand Total Tokens = {grand_total} ===")
